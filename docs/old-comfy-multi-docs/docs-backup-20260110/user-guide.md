# ComfyUI Workshop - User Guide

Welcome to the ComfyUI Multi-User Workshop! This guide will help you get started with creating AI-generated videos and images.

## ğŸ“ Accessing Your Workspace

Each participant has a dedicated workspace:

**Your URL**: `https://workshop.ahelme.net/userXXX/`

Where `XXX` is your assigned user number (001-020).

Example:
- User 1: `https://workshop.ahelme.net/user001/`
- User 10: `https://workshop.ahelme.net/user010/`
- User 20: `https://workshop.ahelme.net/user020/`

## ğŸ¨ Getting Started

### 1. Open Your Workspace

Navigate to your assigned URL in a web browser. You'll see the ComfyUI interface with:
- **Left Panel**: Node library and workflow selector
- **Center Canvas**: Visual workflow editor
- **Right Panel**: Properties and settings
- **Top Bar**: Load/Save buttons and Queue Prompt

### 2. Load a Pre-built Workflow

We've included several pre-built workflows to help you get started:

1. Click the **Load** button (folder icon) in the top-left
2. Navigate to the `/workflows/` directory
3. Select a workflow:
   - `example_workflow.json` - Basic SDXL text-to-image
   - `video_generation.json` - Video generation (if available)
   - `image_upscaling.json` - Enhance image quality

### 3. Customize Your Workflow

**Text Prompts:**
1. Find the "CLIP Text Encode" node (usually blue)
2. Click on the text box
3. Enter your description:
   - Positive prompt: "cinematic sunset over mountains, golden hour, 4k"
   - Negative prompt: "blurry, low quality, distorted"

**Settings:**
- **Steps**: Higher = better quality but slower (20-30 recommended)
- **CFG Scale**: Prompt adherence (7-11 recommended)
- **Seed**: Random number for reproducibility (change for variations)

### 4. Submit Your Job

1. Click **Queue Prompt** button (top-right)
2. Your job is submitted to the shared GPU queue
3. A status overlay appears showing:
   - âœ… Queue position
   - â±ï¸ Estimated wait time
   - ğŸ“Š Job progress

**Important**: Jobs are processed one at a time on the shared GPU. Please be patient!

## ğŸš¦ Queue System

### How It Works

All users share a single H100 GPU. The queue manager ensures fair access:

- **FIFO Mode** (default): First come, first served
- **Round-robin Mode**: Alternates between users
- **Priority Mode**: Instructor can jump the queue for demos

### Queue Status

**While your job is pending:**
- Status: "ğŸ“¤ Job submitted..."
- Position: "You are #3 in queue"

**When your job starts:**
- Status: "âš™ï¸ Processing..."
- Progress updates in real-time

**When complete:**
- Status: "âœ… Complete! Outputs ready"
- Images/videos appear in the output panel

### Canceling Jobs

If you need to cancel a job:
1. Click the **Cancel** button on the status overlay
2. Or ask the instructor to cancel via admin dashboard

## ğŸ“‚ File Management

### Outputs

Generated images and videos are saved automatically:

**Location**: `/outputs/userXXX/`

**Accessing outputs:**
1. Right-click on an output node (e.g., "Save Image")
2. Select "View output"
3. Downloads appear in your browser's download folder

**Persistent Storage**: Your outputs are saved permanently and survive system restarts.

### Uploading Files

To use your own images/videos:

1. Find the "Load Image" or "Load Video" node
2. Click the **Upload** button
3. Select your file (max 500MB)
4. File is saved to `/inputs/userXXX/`

**Supported formats:**
- Images: JPG, PNG, WEBP
- Videos: MP4, MOV, AVI

### Custom Models

If you want to use custom models:
1. Upload model files via the "Load Checkpoint" node
2. Files are saved to `/models/userXXX/`
3. Only you can access your custom models
4. Shared workshop models are available to everyone

## ğŸ› ï¸ Tips & Best Practices

### âš¡ Optimize Queue Time

- **Start simple**: Test with low step counts (10-15) first
- **Batch smartly**: Don't queue many jobs at once
- **Use pre-made workflows**: They're optimized for the GPU

### ğŸ¯ Better Results

- **Be specific**: "portrait of a woman, studio lighting, 50mm lens" beats "woman"
- **Use negative prompts**: "blurry, low quality, distorted" prevents bad outputs
- **Iterate**: Try different seeds to explore variations

### ğŸ’¾ Save Your Work

- **Export workflows**: File â†’ Save to download your custom workflow
- **Name your files**: Use descriptive names for easy retrieval
- **Backup important outputs**: Download your best results

### ğŸ› Troubleshooting

**Problem**: Queue Prompt button does nothing
- **Solution**: Check browser console (F12) for errors, refresh page

**Problem**: Job stuck in "Processing" for >10 minutes
- **Solution**: Ask instructor to check - job may have failed

**Problem**: Can't see my outputs
- **Solution**: Refresh the page or check `/outputs/userXXX/` directory

**Problem**: "Queue is full" error
- **Solution**: Wait for queue to clear, or ask instructor to clear stale jobs

## ğŸ“ Workflow Examples

### Basic Text-to-Image (SDXL)

```
1. CLIP Text Encode (Positive) â†’ KSampler
2. CLIP Text Encode (Negative) â†’ KSampler
3. Load Checkpoint â†’ KSampler
4. Empty Latent Image â†’ KSampler
5. KSampler â†’ VAE Decode
6. VAE Decode â†’ Save Image
```

**Prompt ideas:**
- "cyberpunk city at night, neon lights, rain, cinematic"
- "fantasy landscape, magical forest, ethereal lighting"
- "product photography, white background, studio lighting"

### Image-to-Image Variation

```
1. Load Image â†’ VAE Encode
2. VAE Encode â†’ KSampler (set denoise to 0.5-0.7)
3. CLIP Text Encode â†’ KSampler
4. KSampler â†’ VAE Decode â†’ Save Image
```

**Use cases:**
- Style transfer
- Image enhancement
- Creative variations

### Video Generation

```
1. CLIP Text Encode â†’ Video Model
2. Video Model â†’ Video Output
3. Video Output â†’ Save Video
```

**Tips:**
- Keep videos short (2-4 seconds) for faster processing
- Use descriptive motion prompts: "camera pans left to right"
- Video generation takes 5-10 minutes on average

## âŒ¨ï¸ Keyboard Shortcuts

- **Ctrl+S** / **Cmd+S**: Save workflow
- **Ctrl+O** / **Cmd+O**: Load workflow
- **Ctrl+Enter**: Queue prompt
- **Delete**: Delete selected node
- **Ctrl+C/V**: Copy/paste nodes
- **Mouse wheel**: Zoom in/out
- **Middle mouse drag**: Pan canvas

## ğŸ†˜ Getting Help

**During the workshop:**
- Raise your hand and ask the instructor
- Check the admin dashboard for queue status
- Look at example workflows in `/workflows/` directory

**After the workshop:**
- ComfyUI documentation: https://comfyui-wiki.com/
- Community examples: https://comfyworkflows.com/
- GitHub repository: https://github.com/ahelme/comfy-multi

## ğŸ“Š Understanding the Interface

### Node Types

- **Loaders** (Green): Load models, images, videos
- **Conditioning** (Blue): Text prompts and embeddings
- **Sampling** (Orange): The main generation process
- **Latent** (Pink): Work with latent space
- **Image** (Purple): Image processing
- **Output** (Yellow): Save results

### Connection Colors

- **Purple**: Latent tensors
- **Blue**: Conditioning (prompts)
- **Red**: Models
- **White**: Images
- **Green**: Masks
- **Yellow**: Primitives (numbers, text)

### Status Indicators

- **ğŸŸ¢ Green node**: Ready to execute
- **ğŸ”´ Red node**: Missing input or error
- **ğŸŸ¡ Yellow border**: Currently executing
- **âœ… Checkmark**: Successfully executed

## ğŸ¯ Workshop Goals

By the end of this workshop, you should be able to:

- âœ… Navigate the ComfyUI interface
- âœ… Load and customize pre-built workflows
- âœ… Generate images from text prompts
- âœ… Upload and process your own images
- âœ… Create basic video generations
- âœ… Understand the queue system
- âœ… Troubleshoot common issues

## ğŸŒŸ Advanced Topics (Optional)

### Custom Nodes

ComfyUI supports custom nodes for extended functionality:
- ControlNet: Guided image generation
- IP-Adapter: Style reference
- AnimateDiff: Animation from still images

Ask the instructor if these are available!

### Workflow Sharing

To share your workflow with others:
1. File â†’ Save
2. Upload to ComfyWorkflows.com
3. Share the link with classmates

### API Access

Advanced users can submit jobs via API:
```bash
curl -X POST https://workshop.ahelme.net/api/jobs \
  -H "Content-Type: application/json" \
  -d '{"user_id": "user001", "workflow": {...}}'
```

See API documentation for details.

---

**Happy creating!** ğŸ¨âœ¨

If you have questions, don't hesitate to ask the instructor or check the troubleshooting section above.
